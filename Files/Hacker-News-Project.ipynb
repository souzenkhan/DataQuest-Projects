{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "[Dataset and Documentation](https://www.kaggle.com/datasets/hacker-news/hacker-news-posts)\n",
    "\n",
    "This project uses the Hacker News Posts datset available on Kaggle. \n",
    "The aim of this project is to: \n",
    "1) Analyze whether posts tagged with 'Ask HN' (posts asking Hacker News community as specific question) or 'Show HN' (posts showing the Hacker News community a project, product, or something interesting) receive more comments on average\n",
    "\n",
    "2) Analyze whether posts created at a certain time receive more comments on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('hacker_news.csv') as file: \n",
    "    reader = csv.reader(file)\n",
    "    hn = list(reader)\n",
    "    \n",
    "headers = hn[0]\n",
    "hn = hn[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n",
      "\n",
      "\n",
      "['10482257', 'Title II kills investment? Comcast and other ISPs are now spending more', 'http://arstechnica.com/business/2015/10/comcast-and-other-isps-boost-network-investment-despite-net-neutrality/', '53', '22', 'Deinos', '10/31/2015 9:48']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing the headers\n",
    "print(headers)\n",
    "print('\\n')\n",
    "\n",
    "# printing the first five rows \n",
    "row_index = 0\n",
    "while row_index <= 5: \n",
    "    print(hn[row_index])\n",
    "    print('\\n')\n",
    "    row_index += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of posts starting with 'ask hn' is: 1744.\n",
      "The length of posts starting with 'show hn' is: 1162.\n",
      "The length of other post types is: 17194.\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "for row in hn: \n",
    "    title = row[1].lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else: \n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(f\"The length of posts starting with 'ask hn' is: {len(ask_posts)}.\")\n",
    "print(f\"The length of posts starting with 'show hn' is: {len(show_posts)}.\")\n",
    "print(f\"The length of other post types is: {len(other_posts)}.\")\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the length of 'ask hn' posts receive more coments than show posts. \n",
    "\n",
    "Now, lets determine if ask posts created at a certain time are more likely to attract comments. \n",
    "1) Calculate the amount of ask posts created in each hour of the day, along with the number of comments received. \n",
    "\n",
    "2) Calculate the average number of ask posts receive by hour created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking counts by hour: \n",
      "{9: 45, 13: 85, 10: 59, 14: 107, 16: 108, 23: 68, 12: 73, 17: 100, 15: 116, 21: 109, 20: 80, 2: 58, 18: 109, 3: 54, 5: 46, 19: 110, 1: 60, 22: 71, 8: 48, 4: 47, 0: 55, 6: 44, 7: 34, 11: 58}\n",
      "\n",
      "\n",
      "Checking comments by hour: \n",
      "{9: 251, 13: 1253, 10: 793, 14: 1416, 16: 1814, 23: 543, 12: 687, 17: 1146, 15: 4477, 21: 1745, 20: 1722, 2: 1381, 18: 1439, 3: 421, 5: 464, 19: 1188, 1: 683, 22: 479, 8: 492, 4: 337, 0: 447, 6: 397, 7: 267, 11: 641}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "for row in ask_posts: \n",
    "    row_4_int = int(row[4])\n",
    "    row_append = [row[6], row_4_int]\n",
    "    result_list.append(row_append)\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "# example format '8/16/2016 9:55'\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list: \n",
    "    comments_no = row[1]\n",
    "    datevar = row[0]\n",
    "    \n",
    "    date_check = dt.datetime.strptime(datevar, \"%m/%d/%Y %H:%M\")\n",
    "    hour_check = date_check.hour\n",
    "    if hour_check not in counts_by_hour: \n",
    "        counts_by_hour[hour_check] = 1\n",
    "        comments_by_hour[hour_check] = comments_no\n",
    "    elif hour_check in counts_by_hour: \n",
    "        counts_by_hour[hour_check] += 1\n",
    "        comments_by_hour[hour_check] += comments_no\n",
    "\n",
    "print('Checking counts by hour: ')\n",
    "print(counts_by_hour)\n",
    "print('\\n')\n",
    "print('Checking comments by hour: ')\n",
    "print(comments_by_hour)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a list of lists, calculating the average number of comments per post for posts created during each hour of the day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 5.5777777777777775],\n",
       " [13, 14.741176470588234],\n",
       " [10, 13.440677966101696],\n",
       " [14, 13.233644859813085],\n",
       " [16, 16.796296296296298],\n",
       " [23, 7.985294117647059],\n",
       " [12, 9.41095890410959],\n",
       " [17, 11.46],\n",
       " [15, 38.5948275862069],\n",
       " [21, 16.009174311926607],\n",
       " [20, 21.525],\n",
       " [2, 23.810344827586206],\n",
       " [18, 13.20183486238532],\n",
       " [3, 7.796296296296297],\n",
       " [5, 10.08695652173913],\n",
       " [19, 10.8],\n",
       " [1, 11.383333333333333],\n",
       " [22, 6.746478873239437],\n",
       " [8, 10.25],\n",
       " [4, 7.170212765957447],\n",
       " [0, 8.127272727272727],\n",
       " [6, 9.022727272727273],\n",
       " [7, 7.852941176470588],\n",
       " [11, 11.051724137931034]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour: \n",
    "    avg_by_hour.append([hour, comments_by_hour[hour]/counts_by_hour[hour]])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5777777777777775, 9], [14.741176470588234, 13], [13.440677966101696, 10], [13.233644859813085, 14], [16.796296296296298, 16], [7.985294117647059, 23], [9.41095890410959, 12], [11.46, 17], [38.5948275862069, 15], [16.009174311926607, 21], [21.525, 20], [23.810344827586206, 2], [13.20183486238532, 18], [7.796296296296297, 3], [10.08695652173913, 5], [10.8, 19], [11.383333333333333, 1], [6.746478873239437, 22], [10.25, 8], [7.170212765957447, 4], [8.127272727272727, 0], [9.022727272727273, 6], [7.852941176470588, 7], [11.051724137931034, 11]]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for val in avg_by_hour: \n",
    "    swap_avg_by_hour.append([val[1], val[0]])\n",
    "\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the swap_avg_by_hour list so that the highest value shows up first in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, 15],\n",
       " [23.810344827586206, 2],\n",
       " [21.525, 20],\n",
       " [16.796296296296298, 16],\n",
       " [16.009174311926607, 21],\n",
       " [14.741176470588234, 13],\n",
       " [13.440677966101696, 10],\n",
       " [13.233644859813085, 14],\n",
       " [13.20183486238532, 18],\n",
       " [11.46, 17],\n",
       " [11.383333333333333, 1],\n",
       " [11.051724137931034, 11],\n",
       " [10.8, 19],\n",
       " [10.25, 8],\n",
       " [10.08695652173913, 5],\n",
       " [9.41095890410959, 12],\n",
       " [9.022727272727273, 6],\n",
       " [8.127272727272727, 0],\n",
       " [7.985294117647059, 23],\n",
       " [7.852941176470588, 7],\n",
       " [7.796296296296297, 3],\n",
       " [7.170212765957447, 4],\n",
       " [6.746478873239437, 22],\n",
       " [5.5777777777777775, 9]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments:\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Hours for Ask Posts Comments:\")\n",
    "\n",
    "avg_index = 0 \n",
    "for avg,hr in sorted_swap[:5]:\n",
    "    print(\n",
    "    f\"{dt.datetime.strptime(str(hr), '%H').strftime('%H:%M')}: {avg:.2f} average comments per post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original timezone of the dataset is Eastern Standard Time \n",
    "\n",
    "Converting this to western time we get the most common comments per post in Pacific Standard Time as the following: \n",
    "\n",
    "12:00: 38.59 average comments per post\n",
    "23:00: 23.81 average comments per post\n",
    "17:00: 21.52 average comments per post\n",
    "13:00: 16.80 average comments per post\n",
    "18:00: 16.01 average comments per post\n",
    "\n",
    "so the most popular times (using the 12 hr format are):\n",
    "12:00pm, 11:00 pm, 5pm, 1pm, and 6pm in order "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
